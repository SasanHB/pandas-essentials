{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc564cc0",
   "metadata": {},
   "source": [
    "# üìì Lesson 5: Cleaning Missing and Duplicate Data\n",
    "üìò What you will learn:\n",
    "1. How to identify missing (NaN) values\n",
    "2. How to handle missing data using dropna() and fillna()\n",
    "3. How to detect and remove duplicate rows using drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7210bf93",
   "metadata": {},
   "source": [
    "## üìÅ Step 1: Load the Dataset\n",
    "\n",
    "We use the same dataset as before: Sales_January_2019.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10106072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/Sales_January_2019.csv')\n",
    "\n",
    "# Check basic info\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e81469b",
   "metadata": {},
   "source": [
    "## üîç Step 2: Detect Missing Values\n",
    "To check for missing values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5405fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in each column\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268ea7d",
   "metadata": {},
   "source": [
    "This will show how many null (NaN) values are in each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83928412",
   "metadata": {},
   "source": [
    "## üßπ Step 3: Remove Missing Values\n",
    "You can remove rows with missing values using dropna():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e78df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows that have any missing value\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Confirm no more missing values\n",
    "print(df_cleaned.isnull().sum())\n",
    "\n",
    "# Compare shape before and after\n",
    "print(\"Original rows:\", len(df))\n",
    "print(\"Rows after dropna:\", len(df_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a698717",
   "metadata": {},
   "source": [
    "üìå Note: This may remove valuable rows. Use carefully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7769c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some columns are read as string; convert to numeric\n",
    "df['Quantity Ordered'] = pd.to_numeric(df['Quantity Ordered'], errors='coerce')\n",
    "df['Price Each'] = pd.to_numeric(df['Price Each'], errors='coerce')\n",
    "\n",
    "# Drop rows where conversion failed and became NaN\n",
    "df = df.dropna(subset=['Quantity Ordered', 'Price Each'])\n",
    "\n",
    "# Check types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7fad8b",
   "metadata": {},
   "source": [
    "## üõ† Step 4: Fill Missing Values\n",
    "Instead of dropping rows, you can fill missing values with a default value or strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbded0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Option 1: Fill all NaNs with zero (not always recommended)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/Sales_January_2019.csv')\n",
    "\n",
    "# Fill all NaNs with zero\n",
    "df_filled = df.fillna(0)\n",
    "\n",
    "# Example: Find rows where 'Price Each' was filled with zero\n",
    "result = df_filled.query(\"`Price Each` == 0\")\n",
    "print(result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Fill a specific column with 'Unknown'\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/Sales_January_2019.csv')\n",
    "\n",
    "#Fill a specific column with 'Unknown'\n",
    "df['Purchase Address'] = df['Purchase Address'].fillna('Unknown')\n",
    "\n",
    "# Check rows where value was unknown\n",
    "result = df.query(\"`Purchase Address` == 'Unknown'\")\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd99497",
   "metadata": {},
   "source": [
    "üí° You can use .loc for assignments\n",
    "\n",
    "This makes the assignment explicitly on the DataFrame and avoids ambiguity:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae41f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "df = pd.read_csv('../data/Sales_January_2019.csv')\n",
    "\n",
    "# Replace NaN in 'Purchase Address' with 'Unknown'\n",
    "df.loc['Purchase Address'] = df['Purchase Address'].fillna('Unknown')\n",
    "\n",
    "# Find those rows\n",
    "result = df.query(\"`Purchase Address` == 'Unknown'\")\n",
    "print(result.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d938e",
   "metadata": {},
   "source": [
    "## ‚ùå Step 5: Remove Duplicate Rows\n",
    "Check and remove duplicate rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a3133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"Duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Confirm\n",
    "print(\"Remaining duplicates:\", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85692d77",
   "metadata": {},
   "source": [
    "## üß† Practice Exercises\n",
    "1. Load the file Sales_January_2019.csv\n",
    "2. Count missing values per column\n",
    "3. Drop all rows with missing data\n",
    "4. Convert Quantity Ordered and Price Each to numeric\n",
    "5. Drop rows where those conversions failed\n",
    "6. Count and remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6966cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Sales_January_2019.csv')\n",
    "\n",
    "# 1. Count missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 2. Drop missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# 3. Convert to numeric\n",
    "df['Quantity Ordered'] = pd.to_numeric(df['Quantity Ordered'], errors='coerce')\n",
    "df['Price Each'] = pd.to_numeric(df['Price Each'], errors='coerce')\n",
    "\n",
    "# 4. Drop invalid rows\n",
    "df = df.dropna(subset=['Quantity Ordered', 'Price Each'])\n",
    "\n",
    "# 5. Remove duplicates\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbe2d6a",
   "metadata": {},
   "source": [
    "## üìå Summary\n",
    "In this lesson, you learned:\n",
    "- How to detect and handle missing values\n",
    "- How to use dropna() and fillna() effectively\n",
    "- How to convert strings to numbers with to_numeric()\n",
    "- How to clean up duplicate rows\n",
    "\n",
    "üëâ In the next lesson, you‚Äôll learn how to change data types and use categorical data for optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
